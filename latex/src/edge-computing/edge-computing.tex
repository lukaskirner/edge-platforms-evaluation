\chapter{Edge Computing}\label{chap:edge-computing}
Edge Computing started back in the 1990s when Akamai introduced the first content delivery network (CDN) for accelerating the overall web performance. It is still used today for bringing web content closer and faster to the user. For this, nodes are distributed away from the computing center to be closer to the user or end-device. Thought further edge computing extends the CDN concept by adding cloud computing concepts. Therefore, edge computing is no longer bound to caching web content and can now also be used for arbitrary code execution. To get more benefits out of edge computing, the computing tasks can be moved even further to the user or end-device \cite{Shi2016a}. This tackles various problems which occurred with the recent move to the cloud. The following gives a brief overview which problems get tackled and what are the advantages of doing edge computing.

\bigskip
A very simplified and common architecture of edge computing is shown in figure \ref{fig:hierarchical-cloud-edge-iot}. The lower rectangle represents the \gls{IoT} devices, which can be anything from environmental sensors to video cameras. These devices connect them self to the nearest available edge node of the system. The next level is the edge nodes which do the processing for the IoT devices. Results, gathered by the edge processing of data can then be sent to the cloud, the top most rectangle.

\begin{figure}[H]
    \centering
    \fontsize{9}{10}\selectfont
    \def\svgwidth{\textwidth}
    \input{assets/edge-computing/Cloud-Edge-IoT.pdf_tex}
    \caption{Hierarchical structure of Cloud and Edge computing (Figure adapted from \cite{Infineon2019}).}
    \label{fig:hierarchical-cloud-edge-iot}
\end{figure}

\bigskip
\paragraph{Highly responsive:} The IoT device mostly isn't powerful enough to run the computing process on their own, so they have to send it to a more powerful machine. The default strategy is mostly to offload the task to a cloud infrastructure. But offloading the computing task to a cloud infrastructure comes with some problems in the latency section. With increasing physical distance the latency is also increasing and most of the time the data center isn't next to the sensor device. Edge computing can tackle this by moving the computing near to the sensor device which reduces the overall physical distance and therefore the latency which is added just due to the physical distance \cite{Shi2016a}.

\paragraph{Data Privacy:} Growing concerns about data privacy can be mitigated by shifting the processing of sensitive data closer to the user or factory. With edge computing, the data can be processed inside the owner's trust domain which allows the owner fine grain control about his data. A simple example about how edge computing can protect the owners' privacy is a video camera which sends its captured frames to a data center for evaluation. By doing the evaluation inside the owner's trust domain, in our case edge computing, privacy can be sustained \cite{Shi2016a}.

\paragraph{Masking cloud outages:} Cloud outages like the recent outage at Fastly CDN or the fire at the OVH cloud in France made many services unavailable around the world \cite{Rockwell2021} \cite{Holland2021}. Cloud outages can have different kinds of nature. Wrong configuration, fire, natural disasters, cyberattacks, terrorist attacks, weak networking infrastructure and more. By staying away from the cloud, outages like these won't affect your system. Of course, there are use cases where even the edge computing platform sends its aggregated results to the cloud, but a temporary outage of a cloud can be easily masked by resending the results upon reconnection \cite{Shi2016a}.

\paragraph{More sustainable future:} Data centers consume a lot of energy which generates carbon emissions during production. Even the positive trend of using renewable energy only for operating data centers, an even more sustainable approach can be done by reducing the overall traffic to and from the data centers. Edge Computing can help to greatly reduce the bandwidth usage to cloud data centers by computing the data locally and only sending the relevant data like results or aggregated data to the cloud. It can even completely eliminate any bandwidth usage outside the edge computing network if the use case allows operation without any internet connection or cloud computing support. Even the use of existing hardware is more sustainable. Many existing devices are already capable of doing computational task. Many existing devices have enough computational power for some computational tasks, but this power is mostly not used at all. These underused devices is a waste of potential and resources \cite{ObjectBoxLimited2021} \cite{Adib}.

\paragraph{Scalability:} By doing the processing at the edge not only latency can be reduced also ingress bandwidth to the cloud can be reduced. By processing the data near the user and only sending the results to the cloud, the ingress bandwidth to the cloud can be reduced by a magnitude of three to six orders. A video camera is one example where the bandwidth usage can be extraordinarily high. For example, 12,000 users transmitting a 1080p video would require a link of 100 gigabits per second; a million users would require a link of 8.5 terabits per second. This tremendous amount of bits per second can saturate a metropolitan area network. By offloading the computation of these video streams to nearby edge nodes the bandwidth can be reduced dramatically \cite{Shi2016a}.

\section{Edge and Fog Computing}
By doing some research about edge computing the word combination fog computing, often appears alongside the word combination edge computing. This section covers the subject of the relation between edge and fog computing. By digging into several papers and blog articles the authors come to a different conclusion about the difference between edge and fog computing. Some authors come to the conclusion that fog computing has cloud-like structures. Fog computing structures can be seen as an extra hierarchical layer between cloud and end devices. This additional layer is located in the local network and acts as a preprocessor of the locally collected data. These authors then describe edge computing as a model of directly processing the data on the devices themselves or very close next to them \cite{Ulmen2019}. In conclusion, these authors see fog computing as a kind of micro local data center and edge computing as an on-device computing solution. On the other hand, Cisco defines fog computing as a subtype of edge computing. For them, fog computing refers to decentralization method where nodes get strategically placed between the cloud and edge devices as the other authors do. The only difference is that fog computing is grouped under edge computing \cite{Cisco}. Even the edge computing platforms themselves show that there is no agreement on how edge or fog computing are grouped exactly. For example, the eclipse foundation calls their edge computing platform ioFog \cite{EclipseFoundation}, which hints at fog computing with just its name. On the other hand, the Linux foundation refers to edge computing with its lightweight Kubernetes platform called k3s. Both ioFog and k3s, use similar concepts that why they can be compared here but more about these similar concepts later on \cite{k3s}. For this thesis, we stick to the classification of Cisco where fog computing is a subtype of edge computing.

\section{Summary}
In general, edge computing is the process of performing common cloud computing tasks closer to the user or target devices. The increasing amount of IoT devices and the associated network and computation problems led away from the centralized cloud approach to a decentralization like edge computing \cite{Shi2016a} \cite{Yu2017}.
