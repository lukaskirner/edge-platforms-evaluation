\chapter{Conclusion}
In the following paragraphs a conclusion to each edge computing platform and a general conclusion is given. At the end, a table with hints to which platform you could choose is given.

\paragraph{k3s:} There isn't much to say about k3s. It's simply an edge Kubernetes cluster. If you know Kubernetes you quickly find your way around. The downside of operating a Kubernetes cluster as edge computing platform is mainly the lack of default components which help the developers to e.g. connect local IoT devices. A big disadvantage of k3s is its development time which is highly increased, compared to the other two platforms, due to its lack of default components. On the other side, the biggest advantage of k3s is its versatility and the existing knowledge about Kubernetes among many developers. Compared to the other two platforms k3s has one big key difference to them. K3s is a network of worker nodes whereas the other platforms have individual worker units which are not meant to directly interact with each other.

\paragraph{AWS IoT Greengrass:} The AWS IoT Greengrass platform seems to be the most sophisticated solution of all. The possibility to run applications in various ways like Docker container or as lambda function allows the developer to choose the best option for case. Deploying and running applications on the core devices is made very easy and simple to understand. The ability to fine tune every component, for each core device, allows a wide variety of system control. But there are also downsides which should be kept in mind. For example the option to run applications as serverless functions could be frustrating in some parts. Especially if the developer tries to develop serverless functions for ARM core devices by using an x86 development environment or by using the \gls{AWS} provided tool \gls{SAM}. The most obvious disadvantage, which also includes an advantage in some scenarios, is the deep integration into the \gls{AWS} ecosystem. The advantage is given by the possibility of directly using a big variety of \gls{AWS} services in the cloud. Nevertheless, one must be aware that an extreme vendor lock then exists, which is the most concerning disadvantage. Also the offline capability is quite limited.

\paragraph{ioFog:} ioFog currently feels like an unfinished product. Problems like the mass production of configuration files for a big fleet creates a confusing overhead. Also, direct connections to other microservices is not possible. The IP address of the agent must always be used to connect to other microservices on the same agent. Upon request in the official ioFog community\footnote{\url{https://discuss.iofog.org/t/interservice-communication-with-http-mqtt-and-more/294}}, no statement could be made about this problem either. Some mentioned problems get resolved in future versions of ioFog. For example version 3.0 introduces a template engine for creating more agents and microservices without creating a new file for each \cite{ioFogTemplateEngine}.

\subsection*{Summary}
To sum it up, all three edge computing platforms are able to run workloads on the edge. Especially AWS IoT Greengrass is doing a great job on the edge but with a bade taste of vendor locking. 

On the exact other side is ioFog which lacks some features and is has some questionable methods for the overall configuration. This does not mean ioFog has no future but in its current state it is not recommended to use it in production grade environments. The newer and already announced version 3, which is currently in beta state, will resolve some of the concerns which appeared during this evaluation process. 

The platform k3s seems to be somewhere in the middle. On the one hand it is capable to do everything but on the other hand no default components or SDK's, which can speed up the development process, are given.
    

\input{src/conclusion/which-platform}
